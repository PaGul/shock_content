{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape\n",
    "from keras.layers import Conv2D, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "\n",
    "import sys\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os.path\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def fixed_generator(generator):\n",
    "    for batch in generator:\n",
    "        yield (batch, batch)\n",
    "\n",
    "img_rows, img_cols, img_chns = 256, 256, 3\n",
    "filters = 64\n",
    "num_conv = 3\n",
    "\n",
    "train_data_dir = '/Users/pavelgulaev/Desktop/Диплом/Шок-картинки/train'\n",
    "validation_data_dir = '/Users/pavelgulaev/Desktop/Диплом/Шок-картинки/valid'\n",
    "nb_train_samples = 1514\n",
    "nb_validation_samples = 283\n",
    "epochs = 5\n",
    "batch_size = 70\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    original_img_size = (img_chns, img_rows, img_cols)\n",
    "else:\n",
    "    original_img_size = (img_rows, img_cols, img_chns)\n",
    "latent_dim = 2\n",
    "intermediate_dim = 128\n",
    "epsilon_std = 1.0\n",
    "\n",
    "x = Input(batch_shape=(batch_size,) + original_img_size)\n",
    "conv_1 = Conv2D(img_chns, kernel_size=(2, 2), padding='same', activation='relu')(x)\n",
    "print (conv_1.shape)\n",
    "conv_2 = Conv2D(filters, kernel_size=(2, 2), padding='same', activation='relu', strides=(2, 2))(conv_1)\n",
    "print (conv_2.shape)\n",
    "conv_3 = Conv2D(filters, kernel_size=num_conv, padding='same', activation='relu', strides=1)(conv_2)\n",
    "print (conv_3.shape)\n",
    "conv_4 = Conv2D(filters, kernel_size=num_conv, padding='same', activation='relu', strides=1)(conv_3)\n",
    "print (conv_4.shape)\n",
    "flat = Flatten()(conv_4)\n",
    "print (flat.shape)\n",
    "hidden = Dense(intermediate_dim, activation='relu')(flat)\n",
    "\n",
    "z_mean = Dense(latent_dim)(hidden)\n",
    "z_log_var = Dense(latent_dim)(hidden)\n",
    "\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0., stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var) * epsilon\n",
    "\n",
    "z = Lambda(sampling)([z_mean, z_log_var])\n",
    "\n",
    "decoder_hid = Dense(intermediate_dim, activation='relu')\n",
    "decoder_upsample = Dense(filters * 128 * 128, activation='relu')\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    output_shape = (batch_size, filters, 128, 128)\n",
    "else:\n",
    "    output_shape = (batch_size, 128, 128, filters)\n",
    "\n",
    "decoder_reshape = Reshape(output_shape[1:])\n",
    "decoder_deconv_1 = Conv2DTranspose(filters, kernel_size=num_conv, padding='same', strides=1, activation='relu')\n",
    "decoder_deconv_2 = Conv2DTranspose(filters, num_conv, padding='same', strides=1, activation='relu')\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    output_shape = (batch_size, filters, 257, 257)\n",
    "else:\n",
    "    output_shape = (batch_size, 257, 257, filters)\n",
    "decoder_deconv_3_upsamp = Conv2DTranspose(filters,kernel_size=(3, 3),strides=(2, 2),padding='valid',activation='relu')\n",
    "decoder_mean_squash = Conv2D(img_chns, kernel_size=2, padding='valid', activation='sigmoid')\n",
    "\n",
    "hid_decoded = decoder_hid(z)\n",
    "up_decoded = decoder_upsample(hid_decoded)\n",
    "reshape_decoded = decoder_reshape(up_decoded)\n",
    "deconv_1_decoded = decoder_deconv_1(reshape_decoded)\n",
    "deconv_2_decoded = decoder_deconv_2(deconv_1_decoded)\n",
    "x_decoded_relu = decoder_deconv_3_upsamp(deconv_2_decoded)\n",
    "x_decoded_mean_squash = decoder_mean_squash(x_decoded_relu)\n",
    "\n",
    "\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "    x = K.flatten(x)\n",
    "    x_decoded_mean = K.flatten(x_decoded_mean)\n",
    "    xent_loss = img_rows * img_cols * metrics.binary_crossentropy(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    return xent_loss + kl_loss\n",
    "\n",
    "vae = Model(x, x_decoded_mean_squash)\n",
    "weights_file=\"/nfs/home/pgulyaev/vae.best.hdf5\"\n",
    "if (os.path.isfile(weights_file)):\n",
    "    vae.load_weights(weights_file)\n",
    "vae.compile(optimizer='adadelta', loss=vae_loss)\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(weights_file, verbose=1, save_best_only=True)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_rows, img_cols),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None)\n",
    "\n",
    "oldStdout = sys.stdout\n",
    "fileLog = open('/Users/pavelgulaev/Desktop/Диплом/vae_logFile', 'w')\n",
    "sys.stdout = fileLog\n",
    "vae.fit_generator(\n",
    "        fixed_generator(train_generator),\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=fixed_generator(validation_generator),\n",
    "        validation_steps=nb_validation_samples // batch_size,\n",
    "        callbacks=callbacks_list)\n",
    "sys.stdout = oldStdout"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:keras_tf]",
   "language": "python",
   "name": "conda-env-keras_tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
